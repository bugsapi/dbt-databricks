[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "dbt-databricks"
dynamic = ["version"]
description = "The Databricks adapter plugin for dbt"
readme = "README.md"
license = "Apache-2.0"
requires-python = ">=3.9"
authors = [{ name = "Databricks", email = "feedback@databricks.com" }]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "License :: OSI Approved :: Apache Software License",
    "Operating System :: MacOS :: MacOS X",
    "Operating System :: Microsoft :: Windows",
    "Operating System :: POSIX :: Linux",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]
dependencies = [
    "databricks-sdk==0.17.0",
    "databricks-sql-connector>=3.5.0, <4.0.0",
    "dbt-adapters>=1.7.0, <2.0",
    "dbt-common>=1.10.0, <2.0",
    "dbt-core>=1.8.7, <2.0",
    "dbt-spark>=1.8.0, <2.0",
    "keyring>=23.13.0",
    "pandas<2.2.0",
    "pydantic>=1.10.0, <2",
]

[project.urls]
homepage = "https://github.com/databricks/dbt-databricks"
changelog = "https://github.com/databricks/dbt-databricks/blob/main/CHANGELOG.md"
documentation = "https://docs.getdbt.com/reference/resource-configs/databricks-configs"
issues = "https://github.com/databricks/dbt-databricks/issues"
repository = "https://github.com/databricks/dbt-databricks"

[tool.hatch.version]
path = "dbt/adapters/databricks/__version__.py"

[tool.hatch.build]
include = ["/dbt"]

[tool.hatch.envs.default]
dependencies = [
    "dbt-spark>=1.8.0, <2.0",
    "dbt-core>=1.8.7, <2.0",
    "dbt-common>=1.10.0, <2.0",
    "dbt-adapters>=1.7.0, <2.0",
    "dbt-tests-adapter>=1.10.2, <2.0",
    "pytest-xdist",
    "pytest-dotenv",
    "freezegun",
    "mypy",
    "pre-commit",
    "types-requests",
]

[tool.hatch.envs.default.scripts]
setup = "pre-commit install"
code-quality = "pre-commit run --all-files"
unit = "pytest --color=yes -v -n auto --dist=loadscope tests/unit"
cluster-e2e = "pytest --color=yes -v --profile databricks_cluster -n auto --dist=loadscope tests/functional"
uc-cluster-e2e = "pytest --color=yes -v --profile databricks_uc_cluster -n auto --dist=loadscope tests/functional"
sqlw-e2e = "pytest --color=yes -v --profile databricks_uc_sql_endpoint -n auto --dist=loadscope tests/functional"

[[tool.hatch.envs.default.matrix]]
python = ["3.9", "3.10", "3.11", "3.12"]

[tool.ruff]
line-length = 100
target-version = 'py39'

[tool.ruff.lint]
select = ["E", "W", "F", "I"]
ignore = ["E203"]

[tool.pytest.ini_options]
filterwarnings = [
    "ignore:.*'soft_unicode' has been renamed to 'soft_str'*:DeprecationWarning",
    "ignore:unclosed file .*:ResourceWarning",
]
env_files = ["test.env"]
testpaths = ["tests/unit", "tests/functional"]
markers = [
    "external: mark test as requiring an external location",
    "python: mark test as running a python model",
    "dlt: mark test as running a DLT model",
]

[tool.mypy]
strict_optional = true
no_implicit_optional = true
disallow_untyped_defs = true

[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false

[[tool.mypy.overrides]]
module = ["databricks.*", "agate.*", "jinja2.*", "yaml.*"]
ignore_missing_imports = true
